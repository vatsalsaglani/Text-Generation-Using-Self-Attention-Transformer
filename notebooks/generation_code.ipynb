{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch.optim as optim \n",
    "from Transformer import * \n",
    "from BPE.tokenizer import * \n",
    "from BPE.utilities import * \n",
    "from BPE.vocab_builder import *\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/pickles/vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "inttostr.pkl\t   strtoint.pkl\t\t      vocab_tokens.pkl\nsorted_tokens.pkl  tokenized_screenplays.pkl\n"
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_screenplays = load_pickle(f'{path}/tokenized_screenplays.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "395312"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "len(tokenized_screenplays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "min(tokenized_screenplays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6563"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "max(tokenized_screenplays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_array, seq_length):\n",
    "\n",
    "        self.data_array = data_array\n",
    "        self.seq_length = seq_length\n",
    "        self.total_words = len(self.data_array)\n",
    "        self.req_size = self.total_words - self.seq_length - 1\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.req_size\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "\n",
    "        inp_seq = torch.from_numpy(np.array(self.data_array[ix:ix+self.seq_length]))\n",
    "        op_seq = torch.from_numpy(np.array(self.data_array[ix+1:ix+self.seq_length+1]))\n",
    "\n",
    "        return {'input': inp_seq.long(), 'output': op_seq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inttostr = load_pickle(f'{path}/inttostr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "HEADS = 8\n",
    "DEPTH = 6\n",
    "SEQ_LEN = 256\n",
    "NUM_TOKENS = len(inttostr) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = GeneratorDataset(tokenized_screenplays, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data_set, batch_size=4, shuffle=True, num_workers=100, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerationTransformer(emb = EMBEDDING_DIM, heads = HEADS, depth = DEPTH, seq_length = SEQ_LEN, num_tokens = NUM_TOKENS, device = 'cuda', mask = True, wide = True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generator(epoch, model, dataloader, save_every, path = '../models/'):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_running_loss = 0.0\n",
    "    for ix, batch in enumerate(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input, target = batch['input'], batch['output']\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        input, target = torch.autograd.Variable(input), torch.autograd.Variable(target)\n",
    "\n",
    "        output = model(input)\n",
    "\n",
    "        output = output.transpose(2,1)\n",
    "\n",
    "        loss = F.nll_loss(output, target, reduction = 'mean')\n",
    "\n",
    "        batch_running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = batch_running_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "    t = f\"\"\"\n",
    "    Epoch {epoch}:\n",
    "        Loss {epoch_loss}\n",
    "        Time {time.time() - start_time}\n",
    "    \"\"\"\n",
    "\n",
    "    return epoch_loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 256, 395313])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "op.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 395313, 256])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "op_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inttostrt = load_pickle(f'{path}/inttostr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6571"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(inttostrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "276978",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dcd0ee5ea696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0minttostrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-dcd0ee5ea696>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0minttostrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 276978"
     ]
    }
   ],
   "source": [
    "[inttostrt[c] for c in (torch.argmax(op, dim = 2)[1]).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitmlenvconda641c6c46b6b34dc782deed742137ea0f",
   "display_name": "Python 3.7.6 64-bit ('ml_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}